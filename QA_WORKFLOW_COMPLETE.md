# ğŸ”„ FLUJO DE TRABAJO QA COMPLETO - Design Document

**Fecha**: 2025-11-18
**Autor**: QA Senior Lead Analysis
**Objetivo**: Definir el flujo end-to-end de un QA profesional usando esta herramienta

---

## ğŸ“‹ ÃNDICE

1. [El Flujo QA Profesional - Estado Actual vs Estado Ideal](#1-el-flujo-qa-profesional)
2. [Acceptance Criteria - Checkboxes Interactivos](#2-acceptance-criteria-checkboxes)
3. [Test Cases - EjecuciÃ³n y Tracking](#3-test-cases-ejecuciÃ³n)
4. [Test Coverage - CÃ¡lculo y Utilidad](#4-test-coverage)
5. [Bug Tracking - RelaciÃ³n con Tests](#5-bug-tracking)
6. [Evidencias - Upload y Storage](#6-evidencias)
7. [Reportes - GeneraciÃ³n y DistribuciÃ³n](#7-reportes)
8. [Seguimiento - Dashboards y MÃ©tricas](#8-seguimiento)
9. [Features Faltantes - Gap Analysis Completo](#9-features-faltantes)
10. [Roadmap de ImplementaciÃ³n](#10-roadmap)

---

## 1. EL FLUJO QA PROFESIONAL

### ğŸ¯ Estado Actual vs Estado Ideal

#### **FASE 1: Recibir Requirements** âœ… IMPLEMENTADO

**Estado Actual:**
```
PM/PO â†’ Excel con User Stories â†’ Upload a la herramienta
```

**Flujo:**
1. PM/PO crea Excel con user stories + acceptance criteria
2. QA sube Excel vÃ­a `POST /upload?project_id=PROJ-001`
3. Backend parsea con IA (extrae/limpia acceptance criteria)
4. User stories aparecen en tabla con criterios expandibles

**âœ… LO QUE FUNCIONA:**
- Upload Excel/CSV
- Parse automÃ¡tico de columnas
- AI extraction de acceptance criteria complejos
- VisualizaciÃ³n de criterios con checkboxes (decorativos)

**âŒ LO QUE FALTA:**
- **Marcar criterios como completados** â†’ Para tracking de progreso de desarrollo
- **Editar criterios in-app** â†’ Actualmente solo se pueden editar via re-upload
- **Agregar criterios manualmente** â†’ Sin necesidad de Excel
- **Notificar cuando criterios cambian** â†’ Para que QA sepa que debe re-testear

---

#### **FASE 2: Planificar Testing** âš ï¸ PARCIAL

**Estado Ideal:**
```
User Story â†’ Generar Test Cases con IA â†’ Revisar/Editar â†’ Aprobar â†’ Asignar a QA
```

**Flujo Actual:**
1. QA selecciona user story
2. Click "Generate Test Cases"
3. Configurar: # tests, # scenarios, tipos, usar IA
4. Preview de sugerencias â†’ ReviewModal
5. Editar/eliminar tests
6. "Guardar Todos" â†’ Crea tests en BD

**âœ… LO QUE FUNCIONA:**
- GeneraciÃ³n con IA (Gemini)
- Preview antes de guardar
- Editar titles/descriptions
- Ver Gherkin generado
- Batch save

**âŒ LO QUE FALTA:**
- **Asignar test cases a testers** â†’ Campo `assigned_to` existe en BD pero no en UI
- **Estimar tiempo de ejecuciÃ³n** â†’ Campos `estimated_time_minutes` existen pero no se usan
- **Priorizar test cases** â†’ Â¿QuÃ© ejecutar primero si hay poco tiempo?
- **Agrupar en Test Suites** â†’ Actualmente se agrupan por user story, Â¿y si quiero agrupar por Sprint? Â¿Por feature?
- **Test Case Templates** â†’ Guardar templates para reusar
- **Dependencias entre tests** â†’ Test B requiere que Test A pase primero

---

#### **FASE 3: Ejecutar Tests** âŒ NO IMPLEMENTADO

**Estado Ideal:**
```
QA abre test case â†’ Lee pasos Gherkin â†’ Ejecuta â†’ Marca PASSED/FAILED â†’ Agrega notas/evidencias â†’ Guarda resultado
```

**Flujo Esperado:**

**3.1 Iniciar EjecuciÃ³n**
```typescript
// TestCasesPage
<Button onClick={() => openExecutionModal(testCase)}>
  â–¶ Run Test
</Button>

// Modal: TestExecutionModal
- Test Case ID + Title
- Gherkin steps (read-only)
- Checkbox por cada step: âœ… Pass / âŒ Fail / â­ï¸ Skip
- Contador: 8/10 steps passed
- CronÃ³metro: Timer automÃ¡tico de ejecuciÃ³n
- Campo: Notas de ejecuciÃ³n (textarea)
- Campo: Failure reason (si failed)
- Upload: Evidencias (screenshots, videos, logs)
- Select: Status final â†’ PASSED | FAILED | BLOCKED | SKIPPED
- BotÃ³n: "Save Execution"
```

**3.2 Guardar EjecuciÃ³n**
```python
# POST /test-executions
{
  "test_case_id": "TC-001",
  "executed_by": "qa@example.com",
  "execution_date": "2025-11-18T14:30:00",
  "status": "FAILED",
  "execution_time_minutes": 5,
  "passed_steps": 7,
  "failed_steps": 1,
  "total_steps": 8,
  "notes": "El botÃ³n 'Registrar' no se habilitÃ³ despuÃ©s de completar todos los campos",
  "failure_reason": "UI no respondiÃ³ correctamente a validaciones",
  "evidence_files": ["screenshot_1.png", "network_log.har"],
  "bug_ids": []  // Si se crea bug, se linkea despuÃ©s
}
```

**3.3 Historial de Ejecuciones**
```
Test Case TC-001
â”œâ”€ Execution #1: 2025-11-15 14:00 â†’ FAILED by qa@example.com (5 min)
â”œâ”€ Execution #2: 2025-11-16 10:30 â†’ PASSED by qa@example.com (4 min)
â””â”€ Execution #3: 2025-11-18 14:30 â†’ FAILED by qa@example.com (5 min) â† Latest
```

**âœ… LO QUE EXISTE EN BD:**
- Tabla `test_executions` completa
- Campos: executed_by, execution_time, passed_steps, failed_steps, notes, failure_reason

**âŒ LO QUE FALTA:**
- **UI para ejecutar tests** â†’ Modal de ejecuciÃ³n
- **Timer automÃ¡tico** â†’ Medir tiempo real de ejecuciÃ³n
- **Step-by-step tracking** â†’ Checkbox por cada Given/When/Then
- **Upload de evidencias** â†’ Screenshots, videos, logs
- **Historial de ejecuciones** â†’ Ver todas las ejecuciones pasadas de un test
- **Re-run automÃ¡tico** â†’ "Re-ejecutar test" con pre-fill de datos anteriores
- **Bulk execution** â†’ Ejecutar mÃºltiples tests en secuencia

---

#### **FASE 4: Reportar Bugs** âš ï¸ PARCIAL (Backend completo, Frontend placeholder)

**Estado Ideal:**
```
Test FAILED â†’ Click "Report Bug" â†’ Form pre-fill con datos del test â†’ Upload evidencias â†’ Crear bug â†’ Link bug â†” test
```

**Flujo Esperado:**

**4.1 Desde Test Execution**
```typescript
// Dentro de TestExecutionModal cuando status = FAILED
<Button onClick={() => createBugFromTest()}>
  ğŸ› Report Bug
</Button>

// Abre BugFormModal con datos pre-filled:
{
  title: "[TC-001] BotÃ³n Registrar no se habilita",  // Auto-generado
  test_case_id: "TC-001",
  user_story_id: "US-001",
  severity: "HIGH",  // Sugerido por IA basado en test priority
  priority: "HIGH",
  bug_type: "UI",
  status: "NEW",
  environment: "QA",
  browser: "Chrome 120",  // Detectado automÃ¡ticamente
  os: "Windows 11",
  version: "1.0.0",
  steps_to_reproduce: [
    "Given estoy en la pÃ¡gina 'Formulario - Trial'",  // Copiado de Gherkin
    "When completo todos los campos obligatorios",
    "Then el botÃ³n 'Registrar' NO se habilita"  // Modificado para bug
  ],
  expected_behavior: "El botÃ³n 'Registrar' deberÃ­a habilitarse",
  actual_behavior: "El botÃ³n permanece deshabilitado",
  evidence_files: [...],  // Heredado de test execution
  reported_by: "qa@example.com"
}
```

**4.2 Trazabilidad**
```
Bug BUG-001
â”œâ”€ Originado en: Test Case TC-001
â”œâ”€ Relacionado con: User Story US-001
â”œâ”€ Evidencias: 3 archivos (screenshots + network log)
â””â”€ Status History:
   â”œâ”€ NEW (2025-11-18 14:35) by qa@example.com
   â”œâ”€ ASSIGNED (2025-11-18 15:00) to dev@example.com
   â”œâ”€ IN_PROGRESS (2025-11-18 16:00)
   â”œâ”€ FIXED (2025-11-19 10:00)
   â”œâ”€ TESTING (2025-11-19 11:00) by qa@example.com
   â””â”€ VERIFIED (2025-11-19 11:30) by qa@example.com
```

**4.3 Re-test After Bug Fix**
```
Bug BUG-001 â†’ Status: FIXED
â†“
Notification to QA: "Bug BUG-001 marked as FIXED, ready for re-test"
â†“
QA re-runs Test Case TC-001
â†“
If PASSED:
  - Update bug status â†’ VERIFIED
  - Update test execution â†’ PASSED
  - Increment test pass count
If FAILED:
  - Reopen bug â†’ REOPENED
  - Add comment: "Still failing after fix"
  - Link new execution to bug
```

**âœ… LO QUE EXISTE EN BD:**
- Tabla `bug_reports` completa
- Relaciones: project_id, user_story_id, test_case_id
- Status workflow: NEW â†’ ASSIGNED â†’ IN_PROGRESS â†’ FIXED â†’ TESTING â†’ VERIFIED

**âŒ LO QUE FALTA:**
- **BugsPage UI** â†’ Lista de bugs, filtros, CRUD
- **BugFormModal** â†’ Create/Edit bug
- **Auto-fill desde test failed** â†’ Link bug â†” test automÃ¡tico
- **Notification system** â†’ Avisar cuando bug cambia de estado
- **Bug assignment** â†’ Asignar bugs a developers
- **Re-test workflow** â†’ Flujo de verificaciÃ³n post-fix
- **Bug analytics** â†’ Bugs por severity, por component, por tester

---

#### **FASE 5: Generar Reportes** âš ï¸ PARCIAL (Backend existe, Frontend placeholder)

**Estado Ideal:**
```
Sprint terminÃ³ â†’ QA genera Test Plan â†’ Ejecuta todos los tests â†’ Genera Execution Report â†’ Presenta a stakeholders
```

**Flujo Esperado:**

**5.1 Test Plan (Pre-Execution)**
```
ReportsPage â†’ Select "Test Plan"
â†“
Configure:
- Format: PDF | DOCX | Both
- Include: All tests | Only critical | By test type
- Group by: User Story | Test Type | Priority
â†“
Generate â†’ POST /generate-test-plan?project_id=PROJ-001&format=pdf
â†“
Download: test_plan_PROJ-001_2025-11-18.pdf
```

**Contenido del Test Plan:**
```
1. Project Overview
   - Name, Client, Team, Dates
   - Scope: 15 user stories, 45 test cases

2. Test Strategy
   - Test types: Functional (60%), UI (20%), API (20%)
   - Test approach: Manual + Automated
   - Entry/Exit criteria

3. Test Cases by User Story
   US-001: User Login
   â”œâ”€ TC-001: Valid credentials (FUNCTIONAL, HIGH)
   â”œâ”€ TC-002: Invalid email (FUNCTIONAL, MEDIUM)
   â””â”€ TC-003: Missing password (FUNCTIONAL, HIGH)

4. Test Environment
   - QA: qa.example.com
   - Staging: staging.example.com
   - Production: prod.example.com

5. Schedule
   - Test planning: Nov 1-5
   - Test execution: Nov 6-15
   - Bug fixing: Nov 16-20
   - Re-testing: Nov 21-22
```

**5.2 Execution Report (Post-Execution)**
```
ReportsPage â†’ Select "Execution Report"
â†“
Configure:
- Date range: Nov 6 - Nov 15
- Include: Test results + Bug summary + Metrics
- Format: PDF | DOCX | HTML
â†“
Generate â†’ POST /generate-execution-report?project_id=PROJ-001
â†“
Download: execution_report_PROJ-001_2025-11-18.pdf
```

**Contenido del Execution Report:**
```
1. Executive Summary
   - Total tests: 45
   - Passed: 38 (84%)
   - Failed: 5 (11%)
   - Blocked: 2 (5%)
   - Not Run: 0 (0%)

2. Test Execution Metrics
   - Total execution time: 180 minutes
   - Average test time: 4 minutes
   - Tests per day: 9
   - Pass rate trend: [Chart]

3. Failed Tests
   TC-001: User Login â†’ FAILED (Nov 10, 14:30)
   - Reason: Button not enabled
   - Bug: BUG-001 (FIXED)
   - Re-test: PASSED (Nov 12)

4. Bug Summary
   - Total bugs: 7
   - Critical: 1, High: 3, Medium: 2, Low: 1
   - Fixed: 6, Pending: 1
   - Bug fix rate: 86%

5. Test Coverage
   - User stories covered: 15/15 (100%)
   - Test types: Functional (100%), UI (80%), API (60%)
   - Critical paths: All covered

6. Recommendations
   - API tests need improvement (60% coverage)
   - 1 critical bug pending fix (BUG-003)
   - Consider automation for regression tests
```

**âœ… LO QUE EXISTE:**
- Endpoint: `POST /generate-test-plan`
- Generator: `test_plan_generator.py`
- Formatos: PDF, DOCX

**âŒ LO QUE FALTA:**
- **ReportsPage UI** â†’ Select tipo de reporte, configurar, download
- **Execution Report** â†’ Nuevo tipo de reporte post-ejecuciÃ³n
- **Metrics calculation** â†’ Pass rate, avg time, trends
- **Charts/Graphs** â†’ VisualizaciÃ³n de mÃ©tricas
- **Custom templates** â†’ Plantillas personalizables por cliente
- **Scheduled reports** â†’ Auto-generar reportes semanales/mensuales
- **Email reports** â†’ Enviar reportes automÃ¡ticamente a stakeholders

---

#### **FASE 6: Seguimiento y MÃ©tricas** âŒ NO IMPLEMENTADO

**Estado Ideal:**
```
Dashboard en tiempo real â†’ MÃ©tricas de progreso â†’ Alerts automÃ¡ticas â†’ Retrospectiva
```

**Flujo Esperado:**

**6.1 Dashboard Real-Time**
```
DashboardPage (mejorado)
â”œâ”€ Test Execution Progress
â”‚  â”œâ”€ Total: 45 tests
â”‚  â”œâ”€ Executed: 38 (84%)
â”‚  â”œâ”€ Pending: 7 (16%)
â”‚  â””â”€ Progress bar: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 84%
â”‚
â”œâ”€ Pass Rate (Today/Week/Sprint)
â”‚  â”œâ”€ Today: 12/15 tests â†’ 80%
â”‚  â”œâ”€ This week: 38/45 tests â†’ 84%
â”‚  â””â”€ Trend: â†— +4% vs last week
â”‚
â”œâ”€ Bug Status
â”‚  â”œâ”€ Open: 3 (1 critical, 2 high)
â”‚  â”œâ”€ In Progress: 2
â”‚  â”œâ”€ Fixed: 6
â”‚  â”œâ”€ Verified: 5
â”‚  â””â”€ Avg fix time: 1.2 days
â”‚
â”œâ”€ Test Coverage by Type
â”‚  â”œâ”€ Functional: 100% (30/30)
â”‚  â”œâ”€ UI: 80% (8/10)
â”‚  â””â”€ API: 60% (3/5)
â”‚
â”œâ”€ Critical Alerts
â”‚  â”œâ”€ âš ï¸ 1 critical bug pending (BUG-003)
â”‚  â”œâ”€ âš ï¸ 7 tests not executed yet
â”‚  â””â”€ âœ… All critical paths tested
â”‚
â””â”€ Team Performance
   â”œâ”€ qa@example.com: 25 tests, 92% pass rate
   â””â”€ qa2@example.com: 13 tests, 76% pass rate
```

**6.2 MÃ©tricas Calculadas**

**Test Coverage:**
```python
# Coverage = (Test cases ejecutados / Total test cases) * 100
coverage = (executed_tests / total_tests) * 100

# Por tipo:
functional_coverage = (functional_executed / functional_total) * 100

# Por user story:
story_coverage = (stories_with_tests / total_stories) * 100

# Por acceptance criteria:
criteria_coverage = (criteria_tested / total_criteria) * 100
```

**Pass Rate:**
```python
# Pass rate = (Tests PASSED / Tests ejecutados) * 100
pass_rate = (passed_tests / executed_tests) * 100

# Trend:
if pass_rate_today > pass_rate_yesterday:
    trend = "â†— Improving"
else:
    trend = "â†˜ Declining"
```

**Defect Density:**
```python
# Bugs per user story
defect_density = total_bugs / total_user_stories

# Bugs per test case
bug_ratio = total_bugs / total_test_cases
```

**Average Time:**
```python
# Avg test execution time
avg_test_time = sum(execution_times) / total_executions

# Avg bug fix time
avg_fix_time = sum(fix_times) / total_bugs_fixed
```

**6.3 Alerts AutomÃ¡ticas**
```
Sistema de notificaciones:
â”œâ”€ âš ï¸ Critical bug reported â†’ Email to dev lead
â”œâ”€ âœ… All tests passed â†’ Slack notification
â”œâ”€ âš ï¸ Pass rate dropped below 80% â†’ Alert to QA lead
â”œâ”€ âš ï¸ Test not executed for 3 days â†’ Reminder to assigned QA
â””â”€ âœ… Sprint testing complete â†’ Email report to PM
```

**âœ… LO QUE EXISTE:**
- Endpoint: `GET /projects/{id}/stats`
- Campos bÃ¡sicos: total_user_stories, total_test_cases, total_bugs

**âŒ LO QUE FALTA:**
- **Dashboard charts** â†’ GrÃ¡ficos de tendencias
- **Real-time updates** â†’ WebSocket o polling para actualizar mÃ©tricas
- **Advanced metrics** â†’ Coverage by type, pass rate trends, defect density
- **Alerts system** â†’ Notifications automÃ¡ticas
- **Team performance** â†’ MÃ©tricas por tester
- **Exportar mÃ©tricas** â†’ CSV, Excel para anÃ¡lisis externo

---

## 2. ACCEPTANCE CRITERIA CHECKBOXES

### ğŸ¯ DiseÃ±o Propuesto

**Problema Actual:**
Los checkboxes son decorativos (solo muestran `completed: false` del Excel)

**SoluciÃ³n:**

**2.1 Backend API**
```python
# PUT /user-stories/{story_id}/criteria/{criteria_id}
{
  "completed": true
}

# Response:
{
  "story_id": "US-001",
  "criteria_id": "AC-2",
  "completed": true,
  "completed_by": "qa@example.com",
  "completed_date": "2025-11-18T15:00:00",
  "total_criteria": 3,
  "completed_criteria": 2,
  "completion_percentage": 66.7
}
```

**2.2 Frontend UI**
```typescript
// StoryTable.tsx - Fila expandida
{row.original.acceptance_criteria.map((criterion, index) => (
  <li key={criterion.id || index} className="flex items-start gap-2">
    <input
      type="checkbox"
      checked={criterion.completed}
      onChange={() => handleToggleCriteria(row.original.id, criterion.id)}
      className="cursor-pointer"
    />
    <span className={criterion.completed ? 'text-gray-500 line-through' : ''}>
      {criterion.description}
    </span>
    {criterion.completed && (
      <span className="text-xs text-gray-400">
        âœ… {criterion.completed_by} â€¢ {formatDate(criterion.completed_date)}
      </span>
    )}
  </li>
))}
```

**2.3 Para QuÃ© Sirve**

**Caso de Uso 1: Tracking de Desarrollo**
```
Developer implementa feature â†’ QA verifica cada criterio â†’ Marca como completado
US-001: User Login
â”œâ”€ âœ… AC-1: Email validation â†’ Completed by qa@example.com (Nov 10)
â”œâ”€ âœ… AC-2: Password validation â†’ Completed by qa@example.com (Nov 10)
â””â”€ â¬œ AC-3: Redirect to dashboard â†’ Pending (dev still working)

Progress: 66% â†’ PM sabe que falta implementar 1 criterio
```

**Caso de Uso 2: Re-testing**
```
Bug fix deployed â†’ QA desmarca criterios afectados â†’ Re-verifica â†’ Re-marca
BUG-001 fixed: Button not enabled
â†“
Afecta AC-2: Password validation
â†“
QA desmarca AC-2 â†’ Re-testa â†’ Re-marca si OK
```

**Caso de Uso 3: Acceptance Testing**
```
Sprint Review â†’ PM/PO revisa criterios â†’ Marca "Accepted" si cumple DoD
US-001: User Login
â”œâ”€ âœ… AC-1: Validated by QA (Nov 10)
â”œâ”€ âœ… AC-2: Validated by QA (Nov 10)
â””â”€ âœ… AC-3: Validated by QA (Nov 12)
â†“
Progress: 100% â†’ Story DONE
```

---

## 3. TEST CASES - EJECUCIÃ“N

### ğŸ¯ DiseÃ±o Propuesto: Desplegar Filas

**Problema Actual:**
No se pueden ver detalles de test cases en la tabla, hay que abrir modal

**SoluciÃ³n: Expandable Rows + Execution Tracking**

**3.1 UI Design**
```
TestCasesPage - Tabla de test suites (agrupados por user story)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ US-001: User Login                           3 tests | 2/3 âœ…  â”‚
â”‚ â–¼ Expand to see test cases                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ID    â”‚ Title              â”‚ Type  â”‚ Status  â”‚ Last Run â”‚ âš™ï¸  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚ > TC-001â”‚ Valid credentials  â”‚ FUNC  â”‚ PASSED  â”‚ Nov 15   â”‚ ... â”‚
â”‚ > TC-002â”‚ Invalid email      â”‚ FUNC  â”‚ FAILED  â”‚ Nov 14   â”‚ ... â”‚
â”‚ > TC-003â”‚ Missing password   â”‚ FUNC  â”‚ NOT_RUN â”‚ -        â”‚ ... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Click en chevron ">" de TC-001:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â–¼ TC-001: Verify login with valid credentials                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Type: FUNCTIONAL | Priority: HIGH | Automated: No              â”‚
â”‚                                                                 â”‚
â”‚ ğŸ“„ Gherkin Scenario:                                            â”‚
â”‚   @smoke @regression @positive @happy_path                      â”‚
â”‚   Scenario: Valid credentials                                   â”‚
â”‚     Given estoy en la pÃ¡gina 'Login'                           â”‚
â”‚     When ingreso 'user@example.com' en el campo 'Email'        â”‚
â”‚     And ingreso 'Pass123!' en el campo 'Password'              â”‚
â”‚     And hago clic en el botÃ³n 'Iniciar SesiÃ³n'                â”‚
â”‚     Then deberÃ­a ser redirigido al '/dashboard'                â”‚
â”‚     And deberÃ­a ver el mensaje 'Bienvenido'                    â”‚
â”‚                                                                 â”‚
â”‚ ğŸ“Š Execution History (3):                                       â”‚
â”‚   #3 Nov 15, 14:30 â†’ PASSED by qa@example.com (4 min)         â”‚
â”‚   #2 Nov 14, 10:15 â†’ FAILED by qa@example.com (5 min)         â”‚
â”‚   #1 Nov 13, 16:00 â†’ PASSED by qa@example.com (4 min)         â”‚
â”‚                                                                 â”‚
â”‚ ğŸ”— Related:                                                     â”‚
â”‚   User Story: US-001 - User Login                              â”‚
â”‚   Bugs: BUG-001 (VERIFIED), BUG-005 (OPEN)                    â”‚
â”‚                                                                 â”‚
â”‚ âš™ï¸ Actions:                                                     â”‚
â”‚   [â–¶ Run Test] [âœï¸ Edit] [ğŸ‘ï¸ View Gherkin] [ğŸ—‘ï¸ Delete]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**3.2 Execution Modal (Cuando click "Run Test")**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ§ª Execute Test: TC-001                                         â”‚
â”‚ Valid credentials                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Execution Info:                                                 â”‚
â”‚   Tester: qa@example.com (auto-filled)                         â”‚
â”‚   Start Time: Nov 18, 2025 15:30:00 â±ï¸ 00:03:24 (running)     â”‚
â”‚   Environment: [QA â–¼] Browser: [Chrome 120 â–¼]                  â”‚
â”‚                                                                 â”‚
â”‚ Test Steps:                                                     â”‚
â”‚                                                                 â”‚
â”‚   Given:                                                        â”‚
â”‚   â˜‘ï¸ estoy en la pÃ¡gina 'Login'                                â”‚
â”‚                                                                 â”‚
â”‚   When:                                                         â”‚
â”‚   â˜‘ï¸ ingreso 'user@example.com' en el campo 'Email'            â”‚
â”‚   â˜‘ï¸ ingreso 'Pass123!' en el campo 'Password'                 â”‚
â”‚   â˜‘ï¸ hago clic en el botÃ³n 'Iniciar SesiÃ³n'                   â”‚
â”‚                                                                 â”‚
â”‚   Then:                                                         â”‚
â”‚   â˜‘ï¸ deberÃ­a ser redirigido al '/dashboard'                    â”‚
â”‚   âŒ deberÃ­a ver el mensaje 'Bienvenido'                       â”‚
â”‚      â†³ [Upload Evidence] screenshot_error.png âœ… uploaded      â”‚
â”‚                                                                 â”‚
â”‚   Progress: 5/6 steps passed (83%)                             â”‚
â”‚                                                                 â”‚
â”‚ Final Status: [FAILED â–¼]                                        â”‚
â”‚                                                                 â”‚
â”‚ Failure Reason:                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ El mensaje 'Bienvenido' no apareciÃ³. En su lugar     â”‚   â”‚
â”‚   â”‚ se mostrÃ³ 'Acceso denegado'.                          â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚ Execution Notes:                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ Posible problema con permisos de usuario. El login   â”‚   â”‚
â”‚   â”‚ funciona pero el redirect falla. Verificar roles.    â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚ Evidence Files:                                                 â”‚
â”‚   ğŸ“ screenshot_error.png (2.3 MB) [View] [Delete]             â”‚
â”‚   ğŸ“ network_log.har (1.1 MB) [View] [Delete]                  â”‚
â”‚   [+ Upload More Files]                                         â”‚
â”‚                                                                 â”‚
â”‚ Actions:                                                        â”‚
â”‚   [ğŸ› Report Bug] [ğŸ’¾ Save Execution] [âŒ Cancel]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**3.3 Backend API para Execution**
```python
# POST /test-executions
{
  "test_case_id": "TC-001",
  "executed_by": "qa@example.com",
  "execution_date": "2025-11-18T15:30:00",
  "status": "FAILED",
  "execution_time_minutes": 5,
  "passed_steps": 5,
  "failed_steps": 1,
  "total_steps": 6,
  "environment": "QA",
  "browser": "Chrome 120",
  "os": "Windows 11",
  "notes": "Posible problema con permisos de usuario...",
  "failure_reason": "El mensaje 'Bienvenido' no apareciÃ³...",
  "evidence_files": ["screenshot_error.png", "network_log.har"]
}

# GET /test-cases/{id}/executions
# Retorna historial de ejecuciones

# PUT /test-executions/{id}
# Actualizar ejecuciÃ³n (ej: agregar bug_id despuÃ©s de reportar)
```

---

## 4. TEST COVERAGE

### ğŸ¯ CÃ¡lculo y Utilidad

**DefiniciÃ³n:**
Test Coverage mide quÃ© tan bien estÃ¡n probadas las funcionalidades del sistema.

**4.1 Tipos de Coverage**

**A) User Story Coverage**
```python
# Â¿CuÃ¡ntas user stories tienen al menos 1 test case?
story_coverage = (stories_with_tests / total_stories) * 100

# Ejemplo:
# Total stories: 15
# Stories con tests: 14
# Coverage: 93%
```

**Utilidad:**
- Identificar stories sin tests (riesgo alto)
- Priorizar creaciÃ³n de tests para stories crÃ­ticas
- Reportar a PM: "Nos falta testear 1 user story"

**B) Acceptance Criteria Coverage**
```python
# Â¿CuÃ¡ntos criterios de aceptaciÃ³n tienen tests que los validan?
criteria_coverage = (criteria_tested / total_criteria) * 100

# Ejemplo:
# Total criteria: 45 (de 15 stories, 3 criteria cada una)
# Criteria con tests: 40
# Coverage: 89%
```

**Utilidad:**
- Identificar criterios sin tests (gaps en testing)
- Validar que cada criterio tiene al menos 1 test asociado
- Reportar calidad: "89% de criterios estÃ¡n probados"

**C) Test Type Coverage**
```python
# Â¿QuÃ© % de cada tipo de test tenemos?
functional_coverage = (functional_tests_executed / total_functional_tests) * 100
ui_coverage = (ui_tests_executed / total_ui_tests) * 100
api_coverage = (api_tests_executed / total_api_tests) * 100

# Ejemplo:
# Functional: 30/30 = 100%
# UI: 8/10 = 80%
# API: 3/5 = 60%
```

**Utilidad:**
- Identificar quÃ© tipos de test necesitan mÃ¡s atenciÃ³n
- Balancear estrategia de testing
- Reportar gaps: "Solo 60% de API tests ejecutados"

**D) Execution Coverage**
```python
# Â¿QuÃ© % de tests estÃ¡n ejecutados?
execution_coverage = (executed_tests / total_tests) * 100

# Ejemplo:
# Total tests: 45
# Executed: 38
# Coverage: 84%
```

**Utilidad:**
- Tracking de progreso de testing
- Identificar tests pendientes
- Deadline management: "Nos faltan 7 tests para completar sprint"

**4.2 VisualizaciÃ³n en Dashboard**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š Test Coverage Overview                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ Overall Coverage: 87% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] Good                     â”‚
â”‚                                                             â”‚
â”‚ By Dimension:                                               â”‚
â”‚   User Stories:    93% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘] 14/15 stories tested   â”‚
â”‚   Criteria:        89% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 40/45 criteria tested  â”‚
â”‚   Execution:       84% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 38/45 tests run        â”‚
â”‚                                                             â”‚
â”‚ By Test Type:                                               â”‚
â”‚   Functional: 100% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 30/30 âœ…                   â”‚
â”‚   UI:          80% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘]  8/10 âš ï¸                   â”‚
â”‚   API:         60% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘]  3/5  âš ï¸ Needs attention   â”‚
â”‚                                                             â”‚
â”‚ By Priority:                                                â”‚
â”‚   Critical:   100% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 10/10 âœ…                   â”‚
â”‚   High:        90% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘] 18/20 âœ…                   â”‚
â”‚   Medium:      70% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘]  7/10 âš ï¸                   â”‚
â”‚   Low:         60% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘]  3/5  âš ï¸                   â”‚
â”‚                                                             â”‚
â”‚ Gaps Identified:                                            â”‚
â”‚   âš ï¸ US-015: "Payment Processing" has 0 tests              â”‚
â”‚   âš ï¸ 5 acceptance criteria without tests                    â”‚
â”‚   âš ï¸ API coverage below target (60% vs 80% goal)            â”‚
â”‚                                                             â”‚
â”‚ Recommendation:                                             â”‚
â”‚   Create 5 API tests to reach 80% coverage                 â”‚
â”‚   Add tests for US-015 (critical for release)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**4.3 Backend Calculation**
```python
# GET /projects/{id}/coverage
def calculate_coverage(project_id):
    # User Story Coverage
    total_stories = db.query(UserStoryDB).filter(
        UserStoryDB.project_id == project_id
    ).count()

    stories_with_tests = db.query(UserStoryDB).filter(
        UserStoryDB.project_id == project_id,
        UserStoryDB.test_cases.any()  # Has at least 1 test
    ).count()

    story_coverage = (stories_with_tests / total_stories * 100) if total_stories > 0 else 0

    # Acceptance Criteria Coverage
    total_criteria = db.query(func.sum(UserStoryDB.total_criteria)).filter(
        UserStoryDB.project_id == project_id
    ).scalar() or 0

    # Criteria tested = criteria de stories que tienen tests
    criteria_tested = db.query(func.sum(UserStoryDB.total_criteria)).filter(
        UserStoryDB.project_id == project_id,
        UserStoryDB.test_cases.any()
    ).scalar() or 0

    criteria_coverage = (criteria_tested / total_criteria * 100) if total_criteria > 0 else 0

    # Test Type Coverage
    test_type_coverage = {}
    for test_type in TestType:
        total_type = db.query(TestCaseDB).filter(
            TestCaseDB.project_id == project_id,
            TestCaseDB.test_type == test_type
        ).count()

        executed_type = db.query(TestCaseDB).filter(
            TestCaseDB.project_id == project_id,
            TestCaseDB.test_type == test_type,
            TestCaseDB.status.in_([TestStatus.PASSED, TestStatus.FAILED])
        ).count()

        test_type_coverage[test_type.value] = (executed_type / total_type * 100) if total_type > 0 else 0

    # Overall Coverage (weighted average)
    overall_coverage = (story_coverage + criteria_coverage + execution_coverage) / 3

    return {
        "overall_coverage": overall_coverage,
        "story_coverage": story_coverage,
        "criteria_coverage": criteria_coverage,
        "execution_coverage": execution_coverage,
        "test_type_coverage": test_type_coverage,
        "gaps": identify_gaps(project_id)
    }
```

---

## 5. BUG TRACKING

### ğŸ¯ RelaciÃ³n Test Cases â†” Bugs

**5.1 Trazabilidad**
```
User Story US-001
â”œâ”€ Test Case TC-001
â”‚  â”œâ”€ Execution #1: FAILED (Nov 10)
â”‚  â”‚  â””â”€ Bug BUG-001: Button not enabled
â”‚  â”œâ”€ Execution #2: PASSED (Nov 12) [after fix]
â”‚  â””â”€ Execution #3: FAILED (Nov 15)
â”‚     â””â”€ Bug BUG-005: Redirect URL wrong
â””â”€ Test Case TC-002
   â””â”€ Execution #1: FAILED (Nov 11)
      â””â”€ Bug BUG-002: Email validation missing
```

**5.2 Lifecycle del Bug**
```
1. Test FAILED
   â”œâ”€ QA identifica bug durante ejecuciÃ³n
   â””â”€ Click "Report Bug" en TestExecutionModal

2. Bug Creation
   â”œâ”€ BugFormModal pre-filled con datos del test
   â”œâ”€ QA completa: severity, priority, steps, evidences
   â”œâ”€ Save â†’ POST /bugs
   â””â”€ Auto-link: bug.test_case_id = "TC-001"

3. Bug Assignment
   â”œâ”€ Dev Lead asigna bug a developer
   â”œâ”€ Status: NEW â†’ ASSIGNED
   â””â”€ Notification: "Bug BUG-001 assigned to you"

4. Bug Fix
   â”œâ”€ Developer trabaja en fix
   â”œâ”€ Status: ASSIGNED â†’ IN_PROGRESS
   â”œâ”€ Developer marca: FIXED
   â””â”€ Notification to QA: "BUG-001 ready for re-test"

5. Re-testing
   â”œâ”€ QA re-ejecuta Test Case TC-001
   â”œâ”€ Si PASSED:
   â”‚  â”œâ”€ Update bug status â†’ VERIFIED
   â”‚  â”œâ”€ Update test execution â†’ PASSED
   â”‚  â””â”€ Link execution to bug
   â””â”€ Si FAILED:
      â”œâ”€ Reopen bug â†’ REOPENED
      â”œâ”€ Add comment: "Still failing, see execution #3"
      â””â”€ Back to step 3

6. Closure
   â”œâ”€ All re-tests PASSED
   â”œâ”€ QA marca bug â†’ VERIFIED
   â”œâ”€ Dev Lead cierra bug â†’ CLOSED
   â””â”€ Metrics updated: bug fix time, re-open count
```

**5.3 Backend API**
```python
# POST /bugs (Create from test)
{
  "title": "[TC-001] Button not enabled after completing form",
  "test_case_id": "TC-001",
  "user_story_id": "US-001",
  "severity": "HIGH",
  "priority": "HIGH",
  "bug_type": "UI",
  "status": "NEW",
  "environment": "QA",
  "browser": "Chrome 120",
  "os": "Windows 11",
  "version": "1.0.0",
  "steps_to_reproduce": [
    "Given estoy en la pÃ¡gina 'Formulario - Trial'",
    "When completo todos los campos obligatorios",
    "Then el botÃ³n 'Registrar' NO se habilita (expected: enabled)"
  ],
  "expected_behavior": "El botÃ³n 'Registrar' deberÃ­a habilitarse",
  "actual_behavior": "El botÃ³n permanece deshabilitado",
  "reported_by": "qa@example.com",
  "reported_date": "2025-11-18T15:35:00",
  "evidence_files": ["screenshot_error.png", "network_log.har"]
}

# PUT /bugs/{bug_id}/assign
{
  "assigned_to": "dev@example.com",
  "status": "ASSIGNED"
}

# PUT /bugs/{bug_id}/status
{
  "status": "FIXED",
  "fixed_date": "2025-11-19T10:00:00",
  "fix_notes": "Fixed button enable logic in FormValidator.js"
}

# POST /bugs/{bug_id}/retest
{
  "test_execution_id": "exec-123",
  "status": "VERIFIED" | "REOPENED",
  "verified_by": "qa@example.com",
  "verified_date": "2025-11-19T11:30:00",
  "verification_notes": "Re-tested successfully, all steps pass"
}

# GET /test-cases/{id}/bugs
# Retorna todos los bugs relacionados con un test case

# GET /bugs/{bug_id}/related-tests
# Retorna test cases que encontraron este bug
```

---

## 6. EVIDENCIAS

### ğŸ¯ Upload y Storage

**6.1 Tipos de Evidencias**
```
- Screenshots (.png, .jpg)
- Videos (.mp4, .webm)
- Network logs (.har, .txt)
- Console logs (.txt, .log)
- API responses (.json, .xml)
- Database queries (.sql)
```

**6.2 Upload Flow**
```
TestExecutionModal o BugFormModal
â”œâ”€ Drag & drop area
â”œâ”€ Click "Upload Files"
â”œâ”€ Select multiple files (Cmd/Ctrl + click)
â”œâ”€ Preview thumbnails (for images)
â”œâ”€ Upload progress bar
â””â”€ Store in server

Storage path:
/uploads/{project_id}/evidences/{entity_type}/{entity_id}/
  â”œâ”€ test_executions/
  â”‚  â””â”€ exec-123/
  â”‚     â”œâ”€ screenshot_1.png
  â”‚     â””â”€ network_log.har
  â””â”€ bugs/
     â””â”€ BUG-001/
        â”œâ”€ bug_evidence_1.png
        â””â”€ console_log.txt
```

**6.3 Backend API**
```python
# POST /upload-evidence
# Multipart form data
{
  "entity_type": "test_execution" | "bug",
  "entity_id": "exec-123" | "BUG-001",
  "files": [File, File, ...],
  "uploaded_by": "qa@example.com"
}

# Response:
{
  "uploaded_files": [
    {
      "id": "file-1",
      "filename": "screenshot_error.png",
      "size": 2345678,
      "url": "/api/v1/files/file-1",
      "thumbnail_url": "/api/v1/files/file-1/thumbnail",
      "uploaded_date": "2025-11-18T15:35:00"
    }
  ]
}

# GET /files/{file_id}
# Download file

# GET /files/{file_id}/thumbnail
# Get thumbnail (for images/videos)

# DELETE /files/{file_id}
# Delete evidence file
```

**6.4 Frontend UI**
```typescript
// EvidenceUpload Component
<div className="evidence-upload">
  <div
    className="dropzone"
    onDrop={handleDrop}
    onDragOver={handleDragOver}
  >
    {isDragging ? (
      <p>ğŸ“ Drop files here...</p>
    ) : (
      <>
        <Upload className="w-12 h-12 text-gray-400" />
        <p>Drag & drop files or click to browse</p>
        <p className="text-xs text-gray-500">
          Max 10MB per file. Supported: images, videos, logs
        </p>
      </>
    )}
    <input
      type="file"
      multiple
      accept="image/*,video/*,.har,.log,.txt,.json"
      onChange={handleFileSelect}
      hidden
    />
  </div>

  {/* Uploaded files */}
  <div className="uploaded-files">
    {files.map(file => (
      <div key={file.id} className="file-item">
        {file.type.startsWith('image/') && (
          <img src={file.thumbnail_url} alt={file.filename} />
        )}
        <div className="file-info">
          <p>{file.filename}</p>
          <p className="text-xs">{formatFileSize(file.size)}</p>
        </div>
        <button onClick={() => handleDelete(file.id)}>
          <X className="w-4 h-4" />
        </button>
      </div>
    ))}
  </div>
</div>
```

---

## 7. REPORTES

### ğŸ¯ GeneraciÃ³n y DistribuciÃ³n

**7.1 Tipos de Reportes**

**A) Test Plan (Pre-Execution)**
- âœ… Ya implementado en backend
- âŒ Falta UI en ReportsPage

**B) Execution Summary Report (Post-Execution)**
```
Contenido:
â”œâ”€ Executive Summary
â”‚  â”œâ”€ Pass rate
â”‚  â”œâ”€ Total tests executed
â”‚  â””â”€ Critical bugs found
â”œâ”€ Test Results by Story
â”œâ”€ Failed Tests Details
â”œâ”€ Bug Summary
â””â”€ Recommendations
```

**C) Bug Report (Por Bug)**
- âœ… Ya se genera documento markdown en backend
- âŒ Falta generar PDF/DOCX

**D) Metrics Dashboard Report (Weekly/Monthly)**
```
Contenido:
â”œâ”€ Coverage trends
â”œâ”€ Pass rate trends
â”œâ”€ Bug trends
â”œâ”€ Team performance
â””â”€ Comparison vs previous period
```

**7.2 ReportsPage UI**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“„ Test Reports                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ Generate New Report:                                        â”‚
â”‚                                                             â”‚
â”‚   Report Type: [Test Plan â–¼]                               â”‚
â”‚                                                             â”‚
â”‚   Configuration:                                            â”‚
â”‚     Format: â˜‘ï¸ PDF  â˜‘ï¸ DOCX  â˜ HTML                        â”‚
â”‚     Include: â˜‘ï¸ All test cases                             â”‚
â”‚              â˜ Only critical                               â”‚
â”‚              â˜ Only executed                               â”‚
â”‚     Group by: [User Story â–¼]                               â”‚
â”‚                                                             â”‚
â”‚   [Generate Report]                                         â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ Recent Reports:                                             â”‚
â”‚                                                             â”‚
â”‚   Test Plan - PROJ-001                     Nov 18, 15:00   â”‚
â”‚   ğŸ“„ test_plan_PROJ-001_20251118.pdf (2.3 MB)             â”‚
â”‚   [ğŸ“¥ Download] [ğŸ—‘ï¸ Delete]                               â”‚
â”‚                                                             â”‚
â”‚   Execution Report - Sprint 3              Nov 15, 17:30   â”‚
â”‚   ğŸ“„ execution_report_sprint3.pdf (1.8 MB)                â”‚
â”‚   [ğŸ“¥ Download] [ğŸ—‘ï¸ Delete]                               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**7.3 Auto-Generated Reports**
```python
# Scheduled report generation
# Cron job: Every Friday at 5pm
def generate_weekly_report(project_id):
    report = {
        "type": "weekly_summary",
        "project_id": project_id,
        "week": "2025-W47",
        "generated_date": datetime.now(),
        "data": {
            "tests_executed": 45,
            "pass_rate": 84,
            "bugs_found": 7,
            "bugs_fixed": 6
        }
    }

    # Generate PDF
    pdf_path = generate_pdf(report)

    # Email to stakeholders
    send_email(
        to=project.team_members,
        subject=f"Weekly Test Report - {project.name}",
        body="Please find attached the weekly test report",
        attachment=pdf_path
    )
```

---

## 8. SEGUIMIENTO

### ğŸ¯ Dashboards y MÃ©tricas

**8.1 Dashboard Mejorado**
```
Ya existe DashboardPage bÃ¡sico
Necesita agregar:
â”œâ”€ Charts (pass rate trend, bug trend)
â”œâ”€ Real-time updates
â”œâ”€ Alerts system
â”œâ”€ Team performance
â””â”€ Sprint progress
```

**8.2 Notifications System**
```
Tipos de notificaciones:
â”œâ”€ In-App Notifications
â”‚  â”œâ”€ Bell icon con badge count
â”‚  â”œâ”€ Dropdown list de notificaciones
â”‚  â””â”€ Mark as read
â”œâ”€ Email Notifications
â”‚  â”œâ”€ Bug assigned to you
â”‚  â”œâ”€ Bug status changed
â”‚  â”œâ”€ Test execution failed
â”‚  â””â”€ Weekly report
â””â”€ Slack/Teams Integration (futuro)
```

**8.3 Activity Log**
```
Audit trail de todas las acciones:
â”œâ”€ qa@example.com executed TC-001 â†’ FAILED (Nov 18, 15:30)
â”œâ”€ qa@example.com created BUG-001 (Nov 18, 15:35)
â”œâ”€ dev@example.com marked BUG-001 as FIXED (Nov 19, 10:00)
â”œâ”€ qa@example.com verified BUG-001 â†’ VERIFIED (Nov 19, 11:30)
â””â”€ pm@example.com generated test plan (Nov 18, 16:00)

Utilidad:
- AuditorÃ­a
- Compliance
- Retrospectivas
- Identificar cuellos de botella
```

---

## 9. FEATURES FALTANTES - GAP ANALYSIS COMPLETO

### ğŸš¨ CRÃTICO (Sin esto no se puede completar un ciclo QA)

1. **Test Execution UI** âŒ
   - Modal para ejecutar tests step-by-step
   - Timer automÃ¡tico
   - Upload evidencias durante ejecuciÃ³n
   - Save execution results
   - Backend: âœ… (tabla test_executions existe)
   - Frontend: âŒ (no implementado)

2. **BugsPage** âŒ
   - Lista de bugs con filtros
   - BugFormModal (create/edit)
   - Link bugs â†” tests
   - Bug lifecycle (NEW â†’ VERIFIED)
   - Backend: âœ… (completo)
   - Frontend: âŒ (placeholder)

3. **Acceptance Criteria Toggle** âŒ
   - Checkboxes funcionales (no decorativos)
   - Tracking de progreso de desarrollo
   - Backend: âŒ (falta endpoint PUT)
   - Frontend: âŒ (checkboxes disabled)

### âš ï¸ ALTA PRIORIDAD (Mejora significativa del flujo)

4. **Evidence Upload** âŒ
   - Upload screenshots/videos/logs
   - Storage system
   - Thumbnails para imÃ¡genes
   - Link evidencias a executions/bugs
   - Backend: âŒ (no implementado)
   - Frontend: âŒ (no implementado)

5. **ReportsPage** âŒ
   - UI para generar reportes
   - Config: formato, filtros, grouping
   - Lista de reportes histÃ³ricos
   - Download links
   - Backend: âœ… (test plan generator existe)
   - Frontend: âŒ (placeholder)

6. **Coverage Metrics** âŒ
   - Calculation de diferentes tipos de coverage
   - VisualizaciÃ³n en dashboard
   - Identification de gaps
   - Backend: âŒ (falta endpoint /coverage)
   - Frontend: âŒ (no implementado)

### ğŸ“Š MEDIA PRIORIDAD (Features avanzados)

7. **Test Assignment** âŒ
   - Asignar tests a testers especÃ­ficos
   - Workload balancing
   - Backend: âœ… (campo assigned_to existe)
   - Frontend: âŒ (no se puede asignar)

8. **Notifications System** âŒ
   - In-app notifications
   - Email notifications
   - Alerts automÃ¡ticas
   - Backend: âŒ
   - Frontend: âŒ

9. **Activity Log** âŒ
   - Audit trail completo
   - Timeline de eventos
   - Backend: âŒ
   - Frontend: âŒ

10. **Charts & Graphs** âŒ
    - Pass rate trend
    - Bug trend
    - Coverage over time
    - Team performance
    - Backend: âœ… (datos existen)
    - Frontend: âŒ (no visualizaciÃ³n)

### ğŸ”® BAJA PRIORIDAD (Nice to have)

11. **Test Templates** âŒ
    - Guardar tests como templates
    - Reusar templates
    - Template library

12. **Bulk Operations** âŒ
    - Ejecutar mÃºltiples tests en batch
    - Asignar mÃºltiples tests
    - Cambiar status de mÃºltiples tests

13. **Integration con Tools Externos** âŒ
    - Notion sync (campos existen en BD)
    - Azure DevOps sync (campos existen en BD)
    - JIRA integration
    - Slack/Teams notifications

14. **Automated Test Generation** âŒ
    - Generar cÃ³digo de automation desde Gherkin
    - Playwright/Cypress code generation

15. **AI Assistant** âŒ
    - Chatbot para responder preguntas sobre tests
    - Sugerir mejoras a tests
    - Detectar tests duplicados

---

## 10. ROADMAP DE IMPLEMENTACIÃ“N

### ğŸ—“ï¸ Sprint 1 (Semana 1-2): MVP Execution

**Objetivo**: Poder ejecutar tests y reportar bugs

**Features**:
1. Test Execution UI
   - TestExecutionModal component
   - Step-by-step checkboxes
   - Timer
   - Save execution â†’ POST /test-executions
   - View execution history

2. BugsPage + BugFormModal
   - Lista de bugs con filtros
   - Create/Edit bug
   - Link bug â†” test
   - Bug status workflow

3. Evidence Upload (bÃ¡sico)
   - Upload files (screenshots)
   - Store in server
   - Display in execution/bug forms

**Entregables**:
- QA puede ejecutar un test completo
- QA puede reportar un bug
- QA puede subir evidencias

---

### ğŸ—“ï¸ Sprint 2 (Semana 3-4): Tracking & Metrics

**Objetivo**: Visibilidad de progreso y mÃ©tricas

**Features**:
4. Acceptance Criteria Toggle
   - PUT /user-stories/{id}/criteria/{id}
   - Checkboxes funcionales
   - Progress tracking

5. Test Coverage Calculation
   - GET /projects/{id}/coverage
   - Multiple dimensions (story, criteria, type)
   - VisualizaciÃ³n en dashboard

6. ReportsPage
   - UI para generar reportes
   - Test plan + Execution report
   - Download PDF/DOCX
   - Lista de reportes histÃ³ricos

**Entregables**:
- QA puede ver coverage en tiempo real
- QA puede generar reportes ejecutivos
- PM puede ver progreso de testing

---

### ğŸ—“ï¸ Sprint 3 (Semana 5-6): Collaboration & Notifications

**Objetivo**: Trabajo en equipo y comunicaciÃ³n

**Features**:
7. Test Assignment
   - Asignar tests a testers
   - Workload view
   - Filter "My Tests"

8. Notifications System
   - In-app notifications (bell icon)
   - Email notifications
   - Notification preferences

9. Charts & Dashboards
   - Pass rate trend (line chart)
   - Bug severity distribution (bar chart)
   - Coverage by type (donut chart)
   - Team performance table

**Entregables**:
- MÃºltiples QAs pueden trabajar en paralelo
- Notificaciones automÃ¡ticas de cambios
- Dashboards visuales para stakeholders

---

### ğŸ—“ï¸ Sprint 4+ (Semana 7+): Advanced Features

**Objetivo**: OptimizaciÃ³n y automatizaciÃ³n

**Features**:
10. Activity Log & Audit Trail
11. Test Templates
12. Bulk Operations
13. External Integrations (Notion, Azure, JIRA)
14. AI Assistant

---

## ğŸ“ CONCLUSIÃ“N

**Estado Actual**: Tenemos ~60% del flujo QA implementado

**Lo que funciona muy bien**:
- âœ… Upload user stories con AI
- âœ… GeneraciÃ³n de test cases con AI
- âœ… Multi-proyecto
- âœ… Gherkin editor
- âœ… Backend robusto

**Lo que falta para 100%**:
- âŒ Test execution (crÃ­tico)
- âŒ Bug tracking UI (crÃ­tico)
- âŒ Evidence upload (importante)
- âŒ Reports UI (importante)
- âŒ Coverage metrics (importante)

**Tiempo estimado para MVP completo (Sprint 1+2)**: 3-4 semanas de desarrollo

**Siguientes pasos inmediatos**:
1. Implementar Test Execution UI
2. Implementar BugsPage
3. Implementar Evidence Upload

Con estos 3 features, un QA podrÃ¡ hacer su trabajo completo end-to-end. ğŸš€
