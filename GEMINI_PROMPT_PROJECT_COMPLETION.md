# ğŸ¤– Prompt para Gemini: Completar Proyecto QA Documentation Management

---

## ROL ASIGNADO

Eres un **Senior QA Architecture Consultant & Full-Stack Developer** con 15+ aÃ±os de experiencia en:

- **QA Architecture**: DiseÃ±o de plataformas de testing end-to-end (Selenium, Cypress, TestRail, qTest, Zephyr)
- **Full-Stack Development**: FastAPI + React + TypeScript + PostgreSQL
- **Test Management**: ISTQB Expert Level, Certified Test Manager
- **Product Management**: Experiencia diseÃ±ando herramientas SaaS para equipos QA
- **UX/UI para QA Tools**: Conoces las best practices de interfaces para testers
- **AI Integration**: ImplementaciÃ³n de IA para generaciÃ³n de tests (Gemini, GPT-4)

**Tu misiÃ³n**: Analizar el proyecto actual (testsDocumentationManagement) y proponer el diseÃ±o tÃ©cnico completo de las features faltantes para que cualquier QA profesional pueda ejecutar su flujo de trabajo completo dentro de la herramienta.

---

## CONTEXTO DEL PROYECTO

### ğŸ¯ QuÃ© es testsDocumentationManagement

Una plataforma SaaS multi-proyecto que permite a equipos QA:
1. Importar User Stories desde Excel
2. Generar Test Cases automÃ¡ticamente con IA (Gemini 2.5 Flash)
3. Ejecutar tests manualmente
4. Reportar bugs
5. Generar reportes ejecutivos
6. Hacer tracking de mÃ©tricas de testing

**Tech Stack**:
- **Backend**: Python + FastAPI + SQLAlchemy + SQLite + Gemini AI
- **Frontend**: React + TypeScript + TanStack Table + Tailwind CSS
- **Architecture**: Feature-Sliced Design + Entity-based structure

---

## ESTADO ACTUAL DEL PROYECTO

### âœ… LO QUE YA ESTÃ IMPLEMENTADO (60% completo)

#### **Backend - 100% Multi-Proyecto**
```
âœ… Projects CRUD (crear, listar, editar, borrar con CASCADE)
âœ… User Stories con Acceptance Criteria (AI extraction con Gemini)
âœ… Test Cases con Gherkin (generaciÃ³n con IA, batch processing)
âœ… Bug Reports (CRUD completo, lifecycle workflow)
âœ… Test Executions (tabla en BD, sin UI)
âœ… File Upload Excel/CSV (parse automÃ¡tico + AI cleaning)
âœ… Test Plan Generator (PDF/DOCX, sin UI)
âœ… Multi-proyecto con project_id en todas las entidades
âœ… Gemini AI integration (prompt caching, batching, error handling)
```

**Estructura BD (Completa)**:
```sql
projects (id PK, name, description, client, team_members JSON, status, default_test_types JSON, dates...)
  â”œâ”€ user_stories (id PK, project_id FK, title, description, acceptance_criteria JSON, total_criteria, completed_criteria, completion_percentage, priority, status, epic, sprint...)
  â”‚   â””â”€ test_cases (id PK, project_id FK, user_story_id FK, title, description, test_type, priority, status, gherkin_file_path, automated, execution times...)
  â”‚       â””â”€ test_executions (id PK, test_case_id FK, executed_by, execution_date, status, execution_time_minutes, passed_steps, failed_steps, total_steps, notes, failure_reason, bug_ids)
  â””â”€ bug_reports (id PK, project_id FK, user_story_id FK, test_case_id FK, title, description, severity, priority, bug_type, status, environment, browser, os, version, reported_by, assigned_to, verified_by, dates...)
```

**Endpoints API (35 endpoints implementados)**:
```
âœ… GET/POST/PUT/DELETE /projects
âœ… GET /projects/{id}/stats
âœ… POST /upload?project_id=X (Excel/CSV con AI extraction)
âœ… GET /user-stories?project_id=X
âœ… GET /test-cases?project_id=X
âœ… POST /generate-test-cases/{story_id}/preview (con IA)
âœ… POST /test-cases/batch (batch save)
âœ… GET/PUT /test-cases/{id}/gherkin
âœ… POST /generate-test-plan?project_id=X&format=pdf
âœ… GET/POST/PUT/DELETE /bugs?project_id=X
```

#### **Frontend - 85% Funcional**
```
âœ… ProjectsListPage (landing con cards de proyectos)
âœ… ProjectContext (localStorage + global state)
âœ… DashboardPage (mÃ©tricas bÃ¡sicas, sin polling)
âœ… StoriesPage (tabla con acceptance criteria expandibles)
âœ… TestCasesPage (agrupados por user story, filtros, paginaciÃ³n)
âœ… GenerateModal â†’ ReviewTestCasesModal (workflow de preview/approve)
âœ… GherkinEditor (editar archivos .feature)
âœ… CreateProjectModal, TestCaseFormModal
âœ… Rutas dinÃ¡micas: /projects/:projectId/*
```

**Acceptance Criteria - CÃ³mo Funciona Ahora**:
```typescript
// En StoriesPage, click chevron ">" expande fila
// Muestra lista de acceptance criteria con checkboxes:
âœ“ El usuario puede ingresar email y password  // completed: true (verde, tachado)
â—‹ El sistema valida las credenciales           // completed: false (gris)
â—‹ Redirect exitoso al dashboard                // completed: false

// PROBLEMA: Los checkboxes son DECORATIVOS (disabled)
// Solo muestran el estado del Excel importado
// NO se pueden clickear para marcar como completados
```

**Test Cases Table - Estado Actual**:
```
TestCasesPage muestra test suites agrupados por user story:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ US-001: User Login                  3 tests      â”‚ â† Suite header
â”‚   TC-001  Valid credentials  FUNC  PASSED  ...   â”‚ â† Fila de test
â”‚   TC-002  Invalid email      FUNC  FAILED  ...   â”‚
â”‚   TC-003  Missing password   FUNC  NOT_RUN ...   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

// PROBLEMA: No se pueden desplegar filas para ver:
// - Detalles del test (Gherkin completo)
// - Historial de ejecuciones
// - Bugs relacionados
// - Evidencias adjuntas
```

**AI Generation - Prompt QA Senior Lead**:
```
- Rol: QA Senior Lead con 10+ aÃ±os, ISTQB Advanced
- TÃ©cnicas: BVA, Equivalence Partitioning, Decision Tables, State Transition
- AnÃ¡lisis en 3 pasos: AnÃ¡lisis profundo â†’ PriorizaciÃ³n â†’ GeneraciÃ³n
- DistribuciÃ³n: 40% validaciÃ³n, 30% flujo usuario, 30% edge cases
- Prompt caching (24h TTL, reduce costos 75%)
- Batch generation (15 scenarios por request)
- JSON sanitization automÃ¡tico
```

---

### âŒ LO QUE FALTA (40% pendiente) - TU MISIÃ“N

#### **CRÃTICO - Sin esto NO se puede completar un ciclo QA**

**1. Test Execution UI** âŒ
```
ACTUAL: Tabla test_executions existe en BD pero NO HAY UI para ejecutar tests
IDEAL: QA abre test, lee Gherkin, ejecuta step-by-step, marca PASS/FAIL, sube evidencias, guarda resultado

BACKEND EXISTE: âœ…
- Tabla test_executions completa
- Campos: test_case_id, executed_by, execution_date, status, passed_steps, failed_steps, notes, failure_reason, bug_ids

FRONTEND FALTA: âŒ
- TestExecutionModal component
- Step-by-step checkboxes (marcar cada Given/When/Then como pass/fail)
- Timer automÃ¡tico (medir tiempo de ejecuciÃ³n)
- Upload evidencias (screenshots, videos, logs)
- Save execution â†’ POST /test-executions
- View execution history (lista de ejecuciones pasadas del test)
```

**2. BugsPage + Bug Tracking** âŒ
```
ACTUAL: Backend completo, frontend es placeholder "Coming soon..."
IDEAL: QA reporta bug desde test fallido, asigna a dev, dev marca fixed, QA re-testa y verifica

BACKEND EXISTE: âœ…
- Tabla bug_reports completa
- Endpoints: GET/POST/PUT/DELETE /bugs
- Lifecycle: NEW â†’ ASSIGNED â†’ IN_PROGRESS â†’ FIXED â†’ TESTING â†’ VERIFIED

FRONTEND FALTA: âŒ
- BugsPage con lista de bugs + filtros
- BugFormModal (create/edit)
- Auto-fill desde test failed (link bug â†” test)
- Bug lifecycle workflow (assign, fix, verify)
- Re-test workflow (cuando bug marca FIXED, QA debe re-ejecutar test)
```

**3. Acceptance Criteria - Checkboxes Funcionales** âŒ
```
ACTUAL: Checkboxes son decorativos (disabled)
IDEAL: QA/Dev puede marcar criterios como completados para tracking de progreso

BACKEND FALTA: âŒ
- PUT /user-stories/{story_id}/criteria/{criteria_id}
- Actualizar campo completed: true/false
- Recalcular completion_percentage

FRONTEND FALTA: âŒ
- Habilitar checkboxes (quitar disabled)
- onClick handler â†’ API call
- Mostrar quiÃ©n completÃ³ y cuÃ¡ndo
- Actualizar barra de progreso en tiempo real
```

---

#### **ALTA PRIORIDAD - Mejora significativa del flujo**

**4. Evidence Upload & Storage** âŒ
```
ACTUAL: No hay forma de subir evidencias (screenshots, videos, logs)
IDEAL: QA sube evidencias durante ejecuciÃ³n de test o al reportar bug

BACKEND FALTA: âŒ
- POST /upload-evidence (multipart/form-data)
- Storage: /uploads/{project_id}/evidences/{entity_type}/{entity_id}/
- GET /files/{file_id} (download)
- GET /files/{file_id}/thumbnail (para imÃ¡genes)
- DELETE /files/{file_id}

FRONTEND FALTA: âŒ
- EvidenceUpload component (drag & drop)
- Image thumbnails preview
- File size validation (max 10MB)
- Link evidences a test executions y bugs
```

**5. ReportsPage** âŒ
```
ACTUAL: Backend puede generar test plan PDF/DOCX, pero no hay UI
IDEAL: QA genera reportes (test plan pre-ejecuciÃ³n, execution report post-ejecuciÃ³n), configura formato, descarga

BACKEND EXISTE: âœ…
- POST /generate-test-plan
- test_plan_generator.py (PDF/DOCX)

BACKEND FALTA: âš ï¸
- POST /generate-execution-report (nuevo tipo de reporte)
- Incluir: pass rate, bug summary, metrics, charts

FRONTEND FALTA: âŒ
- ReportsPage UI
- Select tipo reporte, configurar filtros
- Lista de reportes histÃ³ricos
- Download links
```

**6. Test Coverage Calculation** âŒ
```
ACTUAL: Campo test_coverage existe en ProjectDB pero es 0.0 (no se calcula)
IDEAL: Dashboard muestra coverage en tiempo real (story coverage, criteria coverage, execution coverage, type coverage)

BACKEND FALTA: âŒ
- GET /projects/{id}/coverage
- Calcular:
  * Story coverage: (stories con tests / total stories) * 100
  * Criteria coverage: (criterios testeados / total criterios) * 100
  * Execution coverage: (tests ejecutados / total tests) * 100
  * Type coverage: % por test type (FUNCTIONAL, UI, API...)

FRONTEND FALTA: âŒ
- Coverage widgets en Dashboard
- Progress bars por dimensiÃ³n
- IdentificaciÃ³n de gaps (stories sin tests)
```

---

#### **MEDIA PRIORIDAD - Features avanzados**

**7. Test Assignment** âŒ
```
BACKEND EXISTE: âœ… Campo assigned_to en test_cases
FRONTEND FALTA: âŒ UI para asignar tests a testers
```

**8. Notifications System** âŒ
```
- In-app notifications (bell icon)
- Email notifications
- Alerts automÃ¡ticas (bug assigned, test failed, etc.)
```

**9. Charts & Dashboards** âŒ
```
- Pass rate trend (line chart)
- Bug severity distribution (bar chart)
- Coverage by type (donut chart)
```

**10. Activity Log & Audit Trail** âŒ
```
- Timeline de eventos
- QuiÃ©n hizo quÃ© y cuÃ¡ndo
```

---

## PREGUNTAS ESPECÃFICAS QUE DEBES RESPONDER

### 1. Acceptance Criteria Checkboxes

**Pregunta**: Los criterios de aceptaciÃ³n tienen checkboxes pero no se pueden checkear. Â¿Para quÃ© nos servirÃ­a poder marcarlos?

**Contexto Actual**:
```typescript
// StoryTable.tsx - Fila expandida (lÃ­nea 274-295)
{row.original.acceptance_criteria.map((criterion, index) => (
  <li key={criterion.id || index} className="flex items-start gap-2">
    {criterion.completed ? (
      <CheckCircle2 className="w-4 h-4 text-green-600" />  // Decorativo
    ) : (
      <Circle className="w-4 h-4 text-gray-400" />         // Decorativo
    )}
    <span className={criterion.completed ? 'text-gray-500 line-through' : ''}>
      {criterion.description}
    </span>
  </li>
))}
```

**Lo que necesito de ti**:
- DiseÃ±ar el flujo completo: Â¿QuiÃ©n marca criterios (QA, Dev, PM)?
- Â¿QuÃ© informaciÃ³n adicional guardar (completed_by, completed_date)?
- API contract del endpoint PUT
- UI/UX: Â¿Mostrar quiÃ©n completÃ³? Â¿Permitir des-marcar?
- Caso de uso: Â¿Tracking de desarrollo? Â¿Acceptance testing? Â¿Re-testing despuÃ©s de bugs?

---

### 2. Test Cases - Desplegar Filas

**Pregunta**: En la tabla de test cases, Â¿cÃ³mo desplegamos filas para ver detalles y chequear tests?

**Contexto Actual**:
```
Tabla actual muestra:
ID | Title | Type | Status | Last Run | Actions

No se puede expandir para ver:
- Gherkin completo
- Historial de ejecuciones
- Bugs relacionados
- Evidencias
```

**Lo que necesito de ti**:
- DiseÃ±o UI de fila expandida (quÃ© mostrar)
- CÃ³mo se ve el historial de ejecuciones (tabla interna, timeline, cards)
- CÃ³mo se muestran bugs relacionados (chips, lista, links)
- CÃ³mo se muestran evidencias (thumbnails, lista)
- Â¿Permitir ejecutar test directamente desde fila expandida?

---

### 3. Test Coverage

**Pregunta**: Â¿CÃ³mo se calcula el coverage? Â¿Para quÃ© nos servirÃ¡?

**Contexto Actual**:
```python
# ProjectDB tiene campo:
test_coverage: float = 0.0  # Siempre 0, no se calcula
```

**Lo que necesito de ti**:
- Definir TODOS los tipos de coverage relevantes para QA:
  * Story coverage
  * Criteria coverage
  * Execution coverage
  * Test type coverage (functional, UI, API...)
  * Priority coverage (critical, high, medium, low)
  * Â¿Otros?
- FÃ³rmula exacta de cÃ¡lculo para cada uno
- CÃ³mo visualizarlos en Dashboard (widgets, charts, progress bars)
- Thresholds: Â¿QuÃ© es buen coverage? (ej: >80% green, 60-80% yellow, <60% red)
- Utilidad: Â¿Para quÃ© le sirve al QA? Â¿Al PM? Â¿Al Dev Lead?

---

### 4. RelaciÃ³n Test Cases â†” Bugs

**Pregunta**: Â¿CÃ³mo relacionamos test cases a bugs? Â¿CÃ³mo trazamos quÃ© test encontrÃ³ quÃ© bug?

**Contexto Actual**:
```python
# bug_reports tiene:
test_case_id: String FK  # Link opcional a test que encontrÃ³ el bug

# test_executions tiene:
bug_ids: String  # Comma-separated: "BUG-001,BUG-002"
```

**Lo que necesito de ti**:
- Flujo completo:
  1. Test execution FAILED â†’ QA reporta bug
  2. Â¿CÃ³mo se auto-llena BugFormModal con datos del test?
  3. Â¿CÃ³mo se linkea bug â†” test automÃ¡ticamente?
  4. Bug marcado FIXED â†’ Â¿CÃ³mo notificar a QA para re-test?
  5. Re-test PASSED â†’ Â¿CÃ³mo marcar bug VERIFIED automÃ¡ticamente?
  6. Re-test FAILED â†’ Â¿CÃ³mo re-abrir bug automÃ¡ticamente?
- UI/UX: Â¿DÃ³nde se muestra la relaciÃ³n?
  * En TestCasesPage: mostrar bugs relacionados
  * En BugsPage: mostrar test que lo encontrÃ³
  * En test execution history: marcar cuÃ¡l generÃ³ bug
- Â¿Permitir mÃºltiples bugs por test? (un test puede encontrar 2+ bugs)
- Â¿Permitir mÃºltiples tests por bug? (mismo bug reportado por diferentes tests)

---

### 5. Evidencias

**Pregunta**: Â¿CÃ³mo se cargarÃ¡n evidencias (screenshots, videos, logs)? Â¿DÃ³nde se almacenan?

**Contexto Actual**:
```
NO HAY SISTEMA DE EVIDENCIAS
test_executions.evidence_files: array de strings (solo nombres, no storage)
bug_reports.document_path: string (solo path al documento markdown generado)
```

**Lo que necesito de ti**:
- Storage strategy:
  * Â¿Local file system? Â¿S3/Cloud?
  * Estructura de carpetas: /uploads/{project_id}/evidences/{entity_type}/{entity_id}/
  * Â¿LÃ­mites de tamaÃ±o? (ej: max 10MB por archivo, max 50MB por test execution)
- Tipos de archivo soportados:
  * Images: .png, .jpg, .gif
  * Videos: .mp4, .webm
  * Logs: .txt, .log, .har
  * Â¿Otros?
- UI/UX:
  * Drag & drop component
  * Thumbnails para imÃ¡genes/videos
  * Preview modal (lightbox)
  * Download links
- API design:
  * POST /upload-evidence (multipart/form-data)
  * GET /files/{file_id}
  * DELETE /files/{file_id}
  * GET /files/{file_id}/thumbnail
- Metadata tracking:
  * Â¿QuiÃ©n subiÃ³? (uploaded_by)
  * Â¿CuÃ¡ndo? (uploaded_date)
  * Â¿TamaÃ±o? (file_size)
  * Â¿Tipo? (mime_type)

---

### 6. GeneraciÃ³n de Reportes

**Pregunta**: Â¿CÃ³mo se generarÃ¡n los reportes? Â¿QuÃ© tipos de reportes necesitamos?

**Contexto Actual**:
```python
# Backend tiene:
POST /generate-test-plan?project_id=X&format=pdf
- Genera PDF/DOCX con lista de tests
- Sin UI para configurar o descargar

# Frontend:
ReportsPage = placeholder "Coming soon..."
```

**Lo que necesito de ti**:
- Tipos de reportes necesarios:
  1. **Test Plan** (pre-ejecuciÃ³n): Lista de tests a ejecutar
     - Â¿QuÃ© incluir? (stories, tests, gherkin, assignments?)
     - Â¿CÃ³mo agrupar? (por story, por type, por priority?)
  2. **Execution Report** (post-ejecuciÃ³n): Resultados de testing
     - Â¿QuÃ© incluir? (pass rate, failed tests, bugs, metrics?)
     - Â¿CÃ³mo visualizar? (tablas, charts, executive summary?)
  3. **Bug Report** (por bug individual): Detalles de un bug
     - Â¿Ya existe? (sÃ­, bug_report_generator.py genera markdown)
     - Â¿Mejorar? (agregar evidencias, generar PDF?)
  4. **Coverage Report**: Estado de coverage
     - Â¿QuÃ© incluir? (coverage por tipo, gaps, recomendaciones?)
  5. Â¿**Otros reportes**? (metrics dashboard, team performance, sprint summary?)
- ConfiguraciÃ³n de reportes:
  * Filtros (date range, test type, priority, status)
  * Formato (PDF, DOCX, HTML, CSV)
  * Template (corporativo, simple, detallado)
  * Idioma (espaÃ±ol, inglÃ©s)
- UI Design:
  * Select tipo de reporte
  * Config panel (filtros, formato)
  * Preview (opcional)
  * Generate button â†’ Progress bar â†’ Download
  * Lista de reportes histÃ³ricos
- AutomatizaciÃ³n:
  * Â¿Generar reportes automÃ¡ticamente? (weekly, sprint end)
  * Â¿Email automÃ¡tico a stakeholders?
  * Â¿Scheduled reports?

---

### 7. Reportar Bugs

**Pregunta**: Â¿CÃ³mo se reportarÃ¡n bugs? Â¿CuÃ¡l es el workflow completo?

**Contexto Actual**:
```
Backend completo:
- Tabla bug_reports con todos los campos
- Endpoints CRUD
- Status workflow: NEW â†’ ASSIGNED â†’ IN_PROGRESS â†’ FIXED â†’ TESTING â†’ VERIFIED â†’ CLOSED

Frontend:
- BugsPage = placeholder
- BugFormModal = no existe
```

**Lo que necesito de ti**:
- Flujo end-to-end:
  1. **Reportar bug**:
     - Â¿Desde dÃ³nde? (test execution modal, manual desde BugsPage)
     - Form fields (title, description, severity, priority, steps to reproduce, expected vs actual behavior, environment, browser, OS, evidences)
     - Â¿Auto-fill desde test failed? (heredar steps de Gherkin, link test_case_id, link user_story_id)
  2. **Asignar bug**:
     - Â¿QuiÃ©n asigna? (QA Lead, PM, auto-assign?)
     - Â¿A quiÃ©n? (developer del team)
     - Notification al assignee
  3. **Trabajar en bug**:
     - Dev marca status: IN_PROGRESS
     - Dev agrega notas de progreso
     - Dev marca: FIXED
     - Notification a QA: "Bug ready for re-test"
  4. **Re-test**:
     - QA re-ejecuta test case relacionado
     - Si PASSED: marcar bug VERIFIED
     - Si FAILED: re-abrir bug (REOPENED), agregar comment
  5. **Cerrar bug**:
     - PM/QA Lead marca CLOSED
     - Calcular metrics: fix time, re-open count
- UI Design BugsPage:
  * Layout: tabla vs cards vs kanban board?
  * Filtros: severity, priority, status, assigned_to, test_case_id
  * Sort: por date, por severity, por priority
  * Bulk actions: assign mÃºltiples bugs, change status
- BugFormModal:
  * Secciones: Info, Details, Environment, Evidence, Assignment
  * Validation: campos obligatorios
  * Pre-fill logic (cuando viene desde test failed)

---

### 8. Seguimiento

**Pregunta**: Â¿CÃ³mo se harÃ¡ seguimiento a todo esto? Â¿QuÃ© mÃ©tricas y dashboards necesitamos?

**Contexto Actual**:
```
DashboardPage bÃ¡sico con:
- Total user stories, test cases, bugs
- No charts, no trends, no drill-down
```

**Lo que necesito de ti**:
- Dashboard completo:
  1. **Test Execution Progress**:
     - Total tests vs executed
     - Progress bar con %
     - Breakdown por status (PASSED, FAILED, NOT_RUN, BLOCKED)
  2. **Pass Rate**:
     - Today, This Week, This Sprint
     - Trend: â†— improving, â†˜ declining, â†’ stable
     - Line chart (Ãºltimos 7 dÃ­as)
  3. **Bug Status**:
     - Open bugs (count + severity breakdown)
     - In Progress bugs
     - Fixed (pending re-test)
     - Verified/Closed
     - Avg fix time
     - Bug trend (bar chart semanal)
  4. **Coverage Metrics**:
     - Story coverage, criteria coverage, execution coverage
     - Por test type (functional, UI, API)
     - Gaps identified (stories sin tests, criterios sin tests)
  5. **Critical Alerts**:
     - âš ï¸ Critical bugs pending
     - âš ï¸ Tests not executed for > 3 days
     - âš ï¸ Pass rate dropped below threshold
  6. **Team Performance**:
     - Tests executed por tester
     - Avg execution time por tester
     - Bugs found por tester
- Real-time updates:
  * Â¿Polling? Â¿WebSocket?
  * Â¿Cada cuÃ¡nto refrescar? (30 seg, 1 min, manual)
- Notifications:
  * In-app (bell icon con badge count)
  * Email (configurable)
  * Â¿Slack/Teams integration?
- Activity Log:
  * Timeline de eventos
  * Filtros por user, por entity type, por date
  * Export log (CSV, JSON)

---

### 9. Features Faltantes

**Pregunta**: Â¿QuÃ© mÃ¡s detalles como estos nos pueden faltar? Â¿QuÃ© features NO hemos considerado?

**Tu tarea**: Hacer un brainstorming completo y listar:
- Features de QA tools profesionales que NO estÃ¡n en nuestro proyecto
- Pain points comunes de QAs que podrÃ­amos resolver
- Integraciones Ãºtiles (JIRA, Notion, Azure DevOps, Slack, CI/CD)
- Automation (generar cÃ³digo Playwright/Cypress desde Gherkin)
- AI features adicionales (sugerir test data, detectar flaky tests, predecir bugs)

---

### 10. Claridad del Flujo

**Pregunta**: Â¿Tenemos claro el flujo completo? Â¿Falta algo en el user journey?

**Flujo actual diseÃ±ado**:
```
1. PM/PO crea proyecto â†’ Upload Excel con stories
2. QA genera test cases con IA â†’ Review â†’ Approve
3. ??? FALTA: QA ejecuta tests â†’ Marca PASS/FAIL â†’ Sube evidencias
4. ??? FALTA: QA reporta bug desde test failed
5. ??? FALTA: Dev marca bug fixed â†’ QA re-testa
6. ??? FALTA: QA genera reportes (test plan, execution report)
7. ??? FALTA: Dashboard muestra mÃ©tricas en tiempo real
```

**Tu tarea**:
- Validar que el flujo estÃ¡ completo
- Identificar steps missing
- Proponer mejoras (ej: onboarding, templates, bulk operations)

---

## LO QUE NECESITO DE TI - ENTREGABLES

### ğŸ“‹ 1. Documento de DiseÃ±o TÃ©cnico Completo

Para cada feature faltante, proporciona:

**A) User Story & Acceptance Criteria**
```
Como [rol], quiero [acciÃ³n] para [beneficio]

Criterios de AceptaciÃ³n:
- [ ] ...
- [ ] ...
```

**B) API Contract**
```python
# Endpoint: POST /ruta
# Request body:
{
  "field": "value"
}

# Response:
{
  "result": "..."
}

# Errores:
400: "Validation error"
404: "Not found"
```

**C) Database Schema Changes** (si aplica)
```sql
ALTER TABLE ...
ADD COLUMN ...
```

**D) Frontend Component Design**
```typescript
// Component: NombreDelComponente
interface Props {
  // ...
}

// Estado:
const [state, setState] = useState(...)

// LÃ³gica:
// ...

// UI Layout:
<div>
  // Describe estructura visual
</div>
```

**E) UX Flow** (paso a paso)
```
User action 1 â†’ System response 1 â†’ User action 2 â†’ ...
```

---

### ğŸ“Š 2. PriorizaciÃ³n y Roadmap

Organiza las features faltantes en sprints:

**Sprint 1 (MVP Execution)**:
- Features crÃ­ticas para poder ejecutar tests
- Tiempo estimado: X dÃ­as

**Sprint 2 (Tracking & Reports)**:
- Coverage, reportes, mÃ©tricas
- Tiempo estimado: X dÃ­as

**Sprint 3 (Collaboration)**:
- Notifications, assignments, activity log
- Tiempo estimado: X dÃ­as

---

### ğŸ¨ 3. UI/UX Mockups (Textual)

Describe visualmente cÃ³mo se ve cada pantalla:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Header con tÃ­tulo                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚ [SecciÃ³n 1]                             â”‚
â”‚   - Elemento A                          â”‚
â”‚   - Elemento B                          â”‚
â”‚                                         â”‚
â”‚ [SecciÃ³n 2]                             â”‚
â”‚   - Tabla/Form/Card                     â”‚
â”‚                                         â”‚
â”‚ [Actions]                               â”‚
â”‚   [Button 1] [Button 2]                 â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ§ª 4. Test Strategy

Para cada feature:
- Â¿CÃ³mo se prueba? (manual, automated)
- Test cases crÃ­ticos
- Edge cases

---

### ğŸ’¡ 5. Mejores PrÃ¡cticas y Recomendaciones

- Performance considerations
- Security considerations
- Scalability considerations
- UX best practices
- Error handling patterns

---

## FORMATO DE RESPUESTA

Por favor, estructura tu respuesta en secciones claras:

```markdown
# Feature 1: Test Execution UI

## 1. User Story
...

## 2. Acceptance Criteria
...

## 3. Backend API Design
...

## 4. Database Changes
...

## 5. Frontend Component Design
...

## 6. UX Flow
...

## 7. UI Mockup
...

## 8. Implementation Notes
...

## 9. Test Strategy
...

---

# Feature 2: BugsPage
...
```

---

## DOCUMENTACIÃ“N DE REFERENCIA

Lee estos archivos para entender el proyecto:

1. **CLAUDE.md**: DocumentaciÃ³n tÃ©cnica completa actual
2. **QA_WORKFLOW_COMPLETE.md**: Flujo QA ideal diseÃ±ado
3. **PROJECT_STATUS.md**: Estado actual del proyecto
4. **PROMPT_IMPROVEMENT_OPTIONS.md**: Opciones de mejora del prompt de IA

Estructura del cÃ³digo:
- `backend/api/routes.py`: Todos los endpoints
- `backend/database/models.py`: Modelos de BD
- `backend/integrations/gemini_client.py`: Cliente de IA
- `frontend/src/pages/`: PÃ¡ginas de la app
- `frontend/src/features/`: Features modulares
- `frontend/src/widgets/`: Componentes reutilizables

---

## RESTRICCIONES Y CONSIDERACIONES

1. **Tech Stack**: Debe usar FastAPI + React + TypeScript (no cambiar stack)
2. **Database**: SQLite actualmente (diseÃ±ar para ser PostgreSQL-compatible)
3. **AI**: Gemini 2.5 Flash (no cambiar modelo sin justificaciÃ³n fuerte)
4. **Authentication**: Actualmente NO hay login (single-user), diseÃ±ar considerando multi-user futuro
5. **Deployment**: Debe ser fÃ¡cil de deployar (Docker preferiblemente)

---

## PREGUNTAS FINALES PARA TI

Antes de empezar, responde:

1. Â¿Entiendes completamente el proyecto actual y sus capacidades?
2. Â¿Tienes claro quÃ© es lo que falta implementar?
3. Â¿Hay algo del proyecto actual que NO estÃ© claro y necesites que aclare?
4. Â¿EstÃ¡s listo para diseÃ±ar las 10 features faltantes con nivel de detalle implementable?

---

**Â¡ADELANTE! DiseÃ±a el futuro de esta plataforma QA. ğŸš€**
